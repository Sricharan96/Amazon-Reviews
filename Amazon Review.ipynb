{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c63d93ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize,RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.metrics import confusion_matrix,precision_score,recall_score,f1_score,roc_curve,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "086c0390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'economy', 'has', 'seen', 'a', 'drastic', 'downfall']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "word_tokenize('The economy has seen a drastic downfall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c99f1305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'economy',\n",
       " 'has',\n",
       " 'seen',\n",
       " 'a',\n",
       " 'drastic',\n",
       " 'downfall',\n",
       " 'Do',\n",
       " 'you',\n",
       " 'see',\n",
       " 'a',\n",
       " 'recovery',\n",
       " '?']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "word_tokenize('The economy has seen a drastic downfall Do you see a recovery ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0bce5a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15-08-1947', '26-01-1950']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sent='India got independence on 15-08-1947 and constitu.tion came into effect on 26-01-1950'\n",
    "re.findall(r'\\d{1,2}-\\d{1,2}-\\d{4}',sent)#(1,2,4) are the digits that are present on the dates \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4b30c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('Amazon_Reviews.csv')\n",
    "Reviews_df=pd.read_csv('Amazon_Reviews.csv')\n",
    "Reviews_df\n",
    "y=Reviews_df['Label']\n",
    "Reviews_df.drop(columns='Label',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2164b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize\n",
    "#remove the stopwords\n",
    "#lemmatization/stemming\n",
    "\n",
    "tokenizer=RegexpTokenizer(r'\\w+')  #w for words , d for digits\n",
    "#tokenizer.tokenize('The economy has seen a drastic downfall Do you see a recovery ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9265be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_en=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5c240fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WordNetLemmatizer,PorterStemmer\n",
    "\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "stemmer=PorterStemmer()\n",
    "#we either use lemmatizer or stemmer we cannot use both \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8df10f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cactus'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemmer.stem('playing')\n",
    "#stemmer.stem('played')\n",
    "#stemmer.stem('raining')\n",
    "#stemmer.stem('rained')\n",
    "#stemmer.stem('cactus') stemmer can sometimes go wrong by rule based\n",
    "#stemmer.stem('cacti') stemmer  does not always give best results\n",
    "\n",
    "lemmatizer.lemmatize('cacti') # for lemmatizer wordnet is a big advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0c4419f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'see'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#POS\n",
    "lemmatizer.lemmatize('seeing',pos='n')\n",
    "lemmatizer.lemmatize('seeing',pos='v')\n",
    "\n",
    "# 'seeing is believing'--> seeing is a noun\n",
    "# 'I have been seeing you with this comapny for many years now' --> seeing is a verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d6de538d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflation', 'has', 'resulted', 'in', 'much', 'higher', 'lending', 'rates']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessing(review):\n",
    "    tokens=tokenizer.tokenize(review)\n",
    "    return tokens\n",
    "preprocessing('Inflation has resulted in much higher lending rates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7d1ce99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inflation', 'resulted', 'much', 'higher', 'lending', 'rates']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocessing(review):\n",
    "    tokens=tokenizer.tokenize(review) \n",
    "    [token.lower() for token in tokens if token.lower() not in sw_en]\n",
    "    pure_tokens=[token.lower() for token in tokens if token.lower() not in sw_en]\n",
    "    return pure_tokens\n",
    "preprocessing('Inflation has resulted in much higher lending rates')    \n",
    "#sw_en.append('rates') syntax to remove any token we want as stopword\n",
    "#preprocessing('Inflation has resulted in much higher lending rates') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bffa8cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(review):\n",
    "    tokens=tokenizer.tokenize(review) \n",
    "    pure_tokens=[token.lower() for token in tokens if token.lower() not in sw_en]\n",
    "    lemma_tokens=[lemmatizer.lemmatize(token,pos='v') for token in pure_tokens]\n",
    "    #return lemma_tokens # to return otput in the form of srtings\n",
    "    return ' '.join(lemma_tokens) # to return output in the form of a sentence\n",
    "#preprocessing('Inflation has resulted in much higher lending rates') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "baa2e7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      stun even non gamer sound track beautiful pain...\n",
       "1      best soundtrack ever anything read lot review ...\n",
       "2      amaze soundtrack favorite music time hand inte...\n",
       "3      excellent soundtrack truly like soundtrack enj...\n",
       "4      remember pull jaw floor hear play game know di...\n",
       "                             ...                        \n",
       "194    book worth second look book great informative ...\n",
       "195    best game ever game make even amaze game like ...\n",
       "196    guitar absentia due respect ambient music enth...\n",
       "197    stiff smell like dry paint get pay pillow stif...\n",
       "198    review pillow joke send pillow back come close...\n",
       "Name: Review, Length: 199, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reviews_df['Review'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "92221b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split(Reviews_df,y,test_size=0.2,random_state=42)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Reviews_df,y,test_size=0.2,random_state=42)\n",
    "X_train['preprocessed_text']=X_train['Review'].apply(preprocessing)\n",
    "X_test['preprocessed_text']=X_test['Review'].apply(preprocessing)\n",
    "len(X_test['preprocessed_text'])\n",
    "len(X_train['preprocessed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1c9d49f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2348"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf=TfidfVectorizer()\n",
    "tfidf.fit_transform(X_train['preprocessed_text'])\n",
    "X_train_tfidf=tfidf.fit_transform(X_train['preprocessed_text'])\n",
    "X_test_tfidf=tfidf.transform(X_test['preprocessed_text'])\n",
    "X_train_tfidf.toarray()\n",
    "X_test_tfidf.toarray()\n",
    "tfidf.get_feature_names()\n",
    "len(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5667cdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.08915085860572745,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.08816283577206503,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.15550203122379777,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_tfidf.toarray())[0]\n",
    "list(pd.DataFrame(X_train_tfidf.toarray())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5084e10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69230769, 0.85185185])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb=MultinomialNB()\n",
    "mnb.fit(X_train_tfidf,y_train)\n",
    "mnb_pred=mnb.predict(X_test_tfidf)\n",
    "confusion_matrix(y_test,mnb_pred)\n",
    "recall_score(y_test,mnb_pred,average=None)\n",
    "precision_score(y_test,mnb_pred,average=None)\n",
    "f1_score(y_test,mnb_pred,average=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
